{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flirt\n",
    "import os, sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# initialize the root path to the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Stress Detection\n",
    "### Name: Ha Le\n",
    "### Date: 11/02/2022\n",
    "\n",
    "This notebook contains my work for assignment 3, Stress Detection. The dataset used in this notebook is from Bosch, called the WESAD dataset (Schimidt et al.). the goal of this assignment is to classifying moment of stress in a controlled lab settings.\n",
    "\n",
    "## Step 1: Download the Dataset.\n",
    "\n",
    "I have downloaded the dataset from [this](https://ubicomp.eti.uni-siegen.de/home/datasets/icmi18/) link. The dataset is currently in the [data](../data/raw/) folder of this project.\n",
    "\n",
    "## Step 2: Data Cleaning, Segmentation, and Features Extraction.\n",
    "\n",
    "The second step of the project is to clean, segment and extracting features from the dataset. Instead of creating my own pipeline like in assignment 2, I will be using the python package [FLIRT](https://flirt.readthedocs.io/en/latest/index.html) to help accelerate the process.\n",
    "\n",
    "There are 15 participants in this study, labelling from S2 to S17 (except for S12). We will read and perform features extraction on each of the user's dataset, and store them in separate dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HRV features: 100%|██████████| 779/779 [00:07<00:00, 99.94it/s] \n",
      "EDA features: 100%|██████████| 788/788 [00:01<00:00, 560.12it/s]\n",
      "HRV features: 100%|██████████| 748/748 [00:00<00:00, 1033.61it/s]\n",
      "EDA features: 100%|██████████| 773/773 [00:00<00:00, 1223.50it/s]\n",
      "HRV features: 100%|██████████| 778/778 [00:00<00:00, 7925.12it/s]\n",
      "EDA features: 100%|██████████| 800/800 [00:00<00:00, 1921.21it/s]\n",
      "HRV features: 100%|██████████| 699/699 [00:00<00:00, 9545.67it/s]\n",
      "EDA features: 100%|██████████| 756/756 [00:00<00:00, 1856.68it/s]\n",
      "HRV features: 100%|██████████| 809/809 [00:00<00:00, 7078.37it/s]\n",
      "EDA features: 100%|██████████| 833/833 [00:00<00:00, 2057.41it/s]\n",
      "HRV features: 100%|██████████| 641/641 [00:00<00:00, 6934.06it/s]\n",
      "EDA features: 100%|██████████| 650/650 [00:00<00:00, 1762.94it/s]\n",
      "HRV features: 100%|██████████| 655/655 [00:00<00:00, 5457.19it/s]\n",
      "EDA features: 100%|██████████| 664/664 [00:01<00:00, 581.19it/s]\n",
      "HRV features: 100%|██████████| 603/603 [00:00<00:00, 1063.67it/s]\n",
      "EDA features: 100%|██████████| 623/623 [00:00<00:00, 897.91it/s] \n",
      "HRV features: 100%|██████████| 673/673 [00:00<00:00, 6865.74it/s]\n",
      "EDA features: 100%|██████████| 683/683 [00:00<00:00, 1795.44it/s]\n",
      "HRV features: 100%|██████████| 629/629 [00:00<00:00, 932.93it/s]\n",
      "EDA features: 100%|██████████| 647/647 [00:00<00:00, 1171.57it/s]\n",
      "HRV features: 100%|██████████| 663/663 [00:00<00:00, 751.58it/s]\n",
      "EDA features: 100%|██████████| 687/687 [00:00<00:00, 1176.32it/s]\n",
      "HRV features: 100%|██████████| 691/691 [00:00<00:00, 5872.91it/s]\n",
      "EDA features: 100%|██████████| 699/699 [00:00<00:00, 1702.92it/s]\n",
      "HRV features: 100%|██████████| 656/656 [00:00<00:00, 1090.41it/s]\n",
      "EDA features: 100%|██████████| 665/665 [00:00<00:00, 753.44it/s]\n",
      "HRV features: 100%|██████████| 703/703 [00:00<00:00, 1063.56it/s]\n",
      "EDA features: 100%|██████████| 711/711 [00:01<00:00, 565.22it/s]\n",
      "HRV features: 100%|██████████| 710/710 [00:00<00:00, 3922.15it/s]\n",
      "EDA features: 100%|██████████| 724/724 [00:00<00:00, 1808.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ibis</th>\n",
       "      <th>hrv_mean_nni</th>\n",
       "      <th>hrv_median_nni</th>\n",
       "      <th>hrv_range_nni</th>\n",
       "      <th>hrv_sdsd</th>\n",
       "      <th>hrv_rmssd</th>\n",
       "      <th>hrv_nni_50</th>\n",
       "      <th>hrv_pnni_50</th>\n",
       "      <th>hrv_nni_20</th>\n",
       "      <th>hrv_pnni_20</th>\n",
       "      <th>...</th>\n",
       "      <th>eda_phasic_n_above_mean</th>\n",
       "      <th>eda_phasic_n_below_mean</th>\n",
       "      <th>eda_phasic_n_sign_changes</th>\n",
       "      <th>eda_phasic_iqr</th>\n",
       "      <th>eda_phasic_iqr_5_95</th>\n",
       "      <th>eda_phasic_pct_5</th>\n",
       "      <th>eda_phasic_pct_95</th>\n",
       "      <th>eda_phasic_entropy</th>\n",
       "      <th>eda_phasic_perm_entropy</th>\n",
       "      <th>eda_phasic_svd_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:16:25+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850479</td>\n",
       "      <td>2.088944</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>2.098928</td>\n",
       "      <td>4.886732</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.322548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:16:35+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.161415</td>\n",
       "      <td>2.103016</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>2.102312</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.966334</td>\n",
       "      <td>0.315608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:16:45+00:00</th>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.850437</td>\n",
       "      <td>2.054713</td>\n",
       "      <td>0.020745</td>\n",
       "      <td>2.075458</td>\n",
       "      <td>5.233475</td>\n",
       "      <td>0.991959</td>\n",
       "      <td>0.308793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:16:55+00:00</th>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>1.760357</td>\n",
       "      <td>0.331890</td>\n",
       "      <td>2.092247</td>\n",
       "      <td>5.350969</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.325930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:17:05+00:00</th>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.615449</td>\n",
       "      <td>1.123332</td>\n",
       "      <td>0.101401</td>\n",
       "      <td>1.224733</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.993196</td>\n",
       "      <td>0.323172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           num_ibis  hrv_mean_nni  hrv_median_nni  \\\n",
       "2017-05-22 07:16:25+00:00       NaN           NaN             NaN   \n",
       "2017-05-22 07:16:35+00:00       NaN           NaN             NaN   \n",
       "2017-05-22 07:16:45+00:00       7.8           NaN             NaN   \n",
       "2017-05-22 07:16:55+00:00       2.6           NaN             NaN   \n",
       "2017-05-22 07:17:05+00:00       0.4           NaN             NaN   \n",
       "\n",
       "                           hrv_range_nni  hrv_sdsd  hrv_rmssd  hrv_nni_50  \\\n",
       "2017-05-22 07:16:25+00:00            NaN       NaN        NaN         NaN   \n",
       "2017-05-22 07:16:35+00:00            NaN       NaN        NaN         NaN   \n",
       "2017-05-22 07:16:45+00:00            NaN       NaN        NaN         NaN   \n",
       "2017-05-22 07:16:55+00:00            NaN       NaN        NaN         NaN   \n",
       "2017-05-22 07:17:05+00:00            NaN       NaN        NaN         NaN   \n",
       "\n",
       "                           hrv_pnni_50  hrv_nni_20  hrv_pnni_20  ...  \\\n",
       "2017-05-22 07:16:25+00:00          NaN         NaN          NaN  ...   \n",
       "2017-05-22 07:16:35+00:00          NaN         NaN          NaN  ...   \n",
       "2017-05-22 07:16:45+00:00          NaN         NaN          NaN  ...   \n",
       "2017-05-22 07:16:55+00:00          NaN         NaN          NaN  ...   \n",
       "2017-05-22 07:17:05+00:00          NaN         NaN          NaN  ...   \n",
       "\n",
       "                           eda_phasic_n_above_mean  eda_phasic_n_below_mean  \\\n",
       "2017-05-22 07:16:25+00:00                     88.0                    152.0   \n",
       "2017-05-22 07:16:35+00:00                    102.0                    138.0   \n",
       "2017-05-22 07:16:45+00:00                    116.0                    124.0   \n",
       "2017-05-22 07:16:55+00:00                    103.0                    137.0   \n",
       "2017-05-22 07:17:05+00:00                    140.0                    100.0   \n",
       "\n",
       "                           eda_phasic_n_sign_changes  eda_phasic_iqr  \\\n",
       "2017-05-22 07:16:25+00:00                        1.0        0.850479   \n",
       "2017-05-22 07:16:35+00:00                        2.0        1.161415   \n",
       "2017-05-22 07:16:45+00:00                        1.0        0.850437   \n",
       "2017-05-22 07:16:55+00:00                        1.0        0.560326   \n",
       "2017-05-22 07:17:05+00:00                        2.0        0.615449   \n",
       "\n",
       "                           eda_phasic_iqr_5_95  eda_phasic_pct_5  \\\n",
       "2017-05-22 07:16:25+00:00             2.088944          0.009984   \n",
       "2017-05-22 07:16:35+00:00             2.103016         -0.000704   \n",
       "2017-05-22 07:16:45+00:00             2.054713          0.020745   \n",
       "2017-05-22 07:16:55+00:00             1.760357          0.331890   \n",
       "2017-05-22 07:17:05+00:00             1.123332          0.101401   \n",
       "\n",
       "                           eda_phasic_pct_95  eda_phasic_entropy  \\\n",
       "2017-05-22 07:16:25+00:00           2.098928            4.886732   \n",
       "2017-05-22 07:16:35+00:00           2.102312                -inf   \n",
       "2017-05-22 07:16:45+00:00           2.075458            5.233475   \n",
       "2017-05-22 07:16:55+00:00           2.092247            5.350969   \n",
       "2017-05-22 07:17:05+00:00           1.224733                -inf   \n",
       "\n",
       "                           eda_phasic_perm_entropy  eda_phasic_svd_entropy  \n",
       "2017-05-22 07:16:25+00:00                 0.999371                0.322548  \n",
       "2017-05-22 07:16:35+00:00                 0.966334                0.315608  \n",
       "2017-05-22 07:16:45+00:00                 0.991959                0.308793  \n",
       "2017-05-22 07:16:55+00:00                 0.999371                0.325930  \n",
       "2017-05-22 07:17:05+00:00                 0.993196                0.323172  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the dictionary that srote the dataframes of different participants\n",
    "features_dict = {}\n",
    "\n",
    "# read the emphatica data from each participant and use flirt to preprocess the data\n",
    "for id in range(2, 18):\n",
    "    if id == 12:\n",
    "        continue\n",
    "    # ignore the warning of flirt since it can be lengthy to look at\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        features = flirt.simple.get_features_for_empatica_archive(ROOT_DIR + f\"/data/raw/WESAD/S{id}/S{id}_E4_Data.zip\", 60, 10, True, True, False)\n",
    "        # convert the index to datetime\n",
    "        features.index = pd.to_datetime(features.index)\n",
    "        features_dict[id] = features\n",
    "\n",
    "# orint out one dataframe of one participant to see the data\n",
    "features_dict[2].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the package works seemlessly with our dataset!\n",
    "\n",
    "## Step 3: Syncing labels with wearable data\n",
    "Since the dataframes above did not contain any labels, we can't just jump right into classfication yet. We need to extract the labels from the _quest.csv file, and merge the labels into our dataset.\n",
    "\n",
    "First, let's take a look at one of the labels file to see its content:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Subj</th>\n",
       "      <th>S2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># ORDER</td>\n",
       "      <td>Base</td>\n",
       "      <td>TSST</td>\n",
       "      <td>Medi 1</td>\n",
       "      <td>Fun</td>\n",
       "      <td>Medi 2</td>\n",
       "      <td>sRead</td>\n",
       "      <td>fRead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># START</td>\n",
       "      <td>7.08</td>\n",
       "      <td>39.55</td>\n",
       "      <td>70.19</td>\n",
       "      <td>81.25</td>\n",
       "      <td>93.38</td>\n",
       "      <td>54.42</td>\n",
       "      <td>89.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># END</td>\n",
       "      <td>26.32</td>\n",
       "      <td>50.3</td>\n",
       "      <td>77.1</td>\n",
       "      <td>87.47</td>\n",
       "      <td>100.15</td>\n",
       "      <td>56.07</td>\n",
       "      <td>91.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># PANAS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Subj     S2 Unnamed: 2 Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
       "0  # ORDER   Base       TSST     Medi 1        Fun     Medi 2      sRead   \n",
       "1  # START   7.08      39.55      70.19      81.25      93.38      54.42   \n",
       "2    # END  26.32       50.3       77.1      87.47     100.15      56.07   \n",
       "3      NaN    NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4  # PANAS      1          1          3          2          1          3   \n",
       "\n",
       "  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 17  Unnamed: 18  \\\n",
       "0      fRead         NaN         NaN  ...          NaN          NaN   \n",
       "1      89.51         NaN         NaN  ...          NaN          NaN   \n",
       "2      91.15         NaN         NaN  ...          NaN          NaN   \n",
       "3        NaN         NaN         NaN  ...          NaN          NaN   \n",
       "4          1         1.0         1.0  ...          4.0          4.0   \n",
       "\n",
       "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          2.0          2.0          2.0          1.0          2.0   \n",
       "\n",
       "   Unnamed: 24  Unnamed: 25  Unnamed: 26  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          1.0          NaN          NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grasping one of the _quest.csv file and display the data, with ; as the seperator\n",
    "quest = pd.read_csv(ROOT_DIR + \"/data/raw/WESAD/S2/S2_quest.csv\", sep=';')\n",
    "quest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labeling file is a bit messy, but we only want to extract the start and end time of the baseline and the stress task (TSST). The next chunk of code will pull the start and end time for \"Base\" and \"TSST\" for each user and put them into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': {'start': datetime.timedelta(seconds=424, microseconds=800000),\n",
       "  'end': datetime.timedelta(seconds=2373)},\n",
       " 'stress': {'start': datetime.timedelta(seconds=1579, microseconds=200000),\n",
       "  'end': datetime.timedelta(seconds=3018)}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the dictionary that store the start/end time of the baseline and stress period\n",
    "stress_interval_dict = {}\n",
    "\n",
    "# grasp the start and end time from the quest dataframe\n",
    "for user in range(2, 18):\n",
    "    if user == 12:\n",
    "        continue\n",
    "    quest = pd.read_csv(ROOT_DIR + f\"/data/raw/WESAD/S{user}/S{user}_quest.csv\", sep=';')\n",
    "    # we only care about the first 3 columns\n",
    "    quest = quest.iloc[:, :3]\n",
    "    # we only care about the first 3 rows\n",
    "    quest = quest.iloc[:3, :]\n",
    "    # rename the columns into [\"subj\", \"start\", \"end\"]\n",
    "    quest.columns = [\"subj\", \"start\", \"end\"]\n",
    "    # grasp the start_time of the baseline activity, convert it into dateimte delta\n",
    "    start_time = timedelta(minutes=float(quest.iloc[1, 1]))\n",
    "    # grasp the end_time of the baseline activity, convert it into dateimte delta\n",
    "    end_time = timedelta(minutes=float(quest.iloc[1, 2]))\n",
    "    #grasp the start_time of the stress activity, convert it into dateimte delta\n",
    "    start_time_stress = timedelta(minutes=float(quest.iloc[2, 1]))\n",
    "    #grasp the end_time of the stress activity, convert it into dateimte delta\n",
    "    end_time_stress = timedelta(minutes=float(quest.iloc[2, 2]))\n",
    "    # put the start_time and end_time into the dictionary\n",
    "    stress_interval_dict[user] = {\"baseline\": {\"start\": start_time, \"end\": end_time}, \"stress\": {\"start\": start_time_stress, \"end\": end_time_stress}}\n",
    "\n",
    "# print out the results of user 2\n",
    "stress_interval_dict[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to grasp the start time of the experiment for each user, which can be inferred as the index of the first row for the emphatica dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-22 07:16:25+0000', tz='UTC', freq='10S')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the dictionary that store the start time of the experiment for each participant\n",
    "start_time_dict = {}\n",
    "\n",
    "for user in range(2, 18):\n",
    "    if user == 12:\n",
    "        continue\n",
    "    # the start time of the experiment is the index of the first row of the features dataframe\n",
    "    start_time = features_dict[user].index[0]\n",
    "    # put the start time into the dictionary\n",
    "    start_time_dict[user] = start_time\n",
    "\n",
    "# print out the start time of user 2\n",
    "start_time_dict[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each user, we want to get only the baseline and the stress period, label them, and put all the stress/baseline timestamp into one common dataframe (with data from all the user). We can get rid of the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>num_ibis</th>\n",
       "      <th>hrv_mean_nni</th>\n",
       "      <th>hrv_median_nni</th>\n",
       "      <th>hrv_range_nni</th>\n",
       "      <th>hrv_sdsd</th>\n",
       "      <th>hrv_rmssd</th>\n",
       "      <th>hrv_nni_50</th>\n",
       "      <th>hrv_pnni_50</th>\n",
       "      <th>hrv_nni_20</th>\n",
       "      <th>...</th>\n",
       "      <th>eda_phasic_n_below_mean</th>\n",
       "      <th>eda_phasic_n_sign_changes</th>\n",
       "      <th>eda_phasic_iqr</th>\n",
       "      <th>eda_phasic_iqr_5_95</th>\n",
       "      <th>eda_phasic_pct_5</th>\n",
       "      <th>eda_phasic_pct_95</th>\n",
       "      <th>eda_phasic_entropy</th>\n",
       "      <th>eda_phasic_perm_entropy</th>\n",
       "      <th>eda_phasic_svd_entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:23:35+00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>61.8</td>\n",
       "      <td>767.133553</td>\n",
       "      <td>775.0356</td>\n",
       "      <td>234.3860</td>\n",
       "      <td>47.967353</td>\n",
       "      <td>47.996281</td>\n",
       "      <td>15.4</td>\n",
       "      <td>24.735490</td>\n",
       "      <td>36.6</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>0.040621</td>\n",
       "      <td>-0.004735</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.957863</td>\n",
       "      <td>0.589850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:23:45+00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>57.2</td>\n",
       "      <td>773.805869</td>\n",
       "      <td>781.2860</td>\n",
       "      <td>234.3860</td>\n",
       "      <td>42.033322</td>\n",
       "      <td>42.051298</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.384988</td>\n",
       "      <td>33.2</td>\n",
       "      <td>...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>4.933534</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>0.587246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:23:55+00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>778.318170</td>\n",
       "      <td>781.2860</td>\n",
       "      <td>234.3860</td>\n",
       "      <td>41.279268</td>\n",
       "      <td>41.281592</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.478992</td>\n",
       "      <td>30.8</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>-0.001636</td>\n",
       "      <td>0.039409</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.875543</td>\n",
       "      <td>0.591086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:24:05+00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>52.8</td>\n",
       "      <td>792.254337</td>\n",
       "      <td>790.6610</td>\n",
       "      <td>215.6348</td>\n",
       "      <td>39.361808</td>\n",
       "      <td>39.396494</td>\n",
       "      <td>8.8</td>\n",
       "      <td>16.732026</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.034263</td>\n",
       "      <td>-0.004960</td>\n",
       "      <td>0.029303</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.726963</td>\n",
       "      <td>0.736138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22 07:24:15+00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>800.842850</td>\n",
       "      <td>796.9110</td>\n",
       "      <td>221.8846</td>\n",
       "      <td>40.378157</td>\n",
       "      <td>40.442510</td>\n",
       "      <td>9.8</td>\n",
       "      <td>17.112367</td>\n",
       "      <td>35.4</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>0.047757</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.047751</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.709955</td>\n",
       "      <td>0.680942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user  num_ibis  hrv_mean_nni  hrv_median_nni  \\\n",
       "2017-05-22 07:23:35+00:00     2      61.8    767.133553        775.0356   \n",
       "2017-05-22 07:23:45+00:00     2      57.2    773.805869        781.2860   \n",
       "2017-05-22 07:23:55+00:00     2      53.0    778.318170        781.2860   \n",
       "2017-05-22 07:24:05+00:00     2      52.8    792.254337        790.6610   \n",
       "2017-05-22 07:24:15+00:00     2      57.0    800.842850        796.9110   \n",
       "\n",
       "                           hrv_range_nni   hrv_sdsd  hrv_rmssd  hrv_nni_50  \\\n",
       "2017-05-22 07:23:35+00:00       234.3860  47.967353  47.996281        15.4   \n",
       "2017-05-22 07:23:45+00:00       234.3860  42.033322  42.051298        10.0   \n",
       "2017-05-22 07:23:55+00:00       234.3860  41.279268  41.281592         9.2   \n",
       "2017-05-22 07:24:05+00:00       215.6348  39.361808  39.396494         8.8   \n",
       "2017-05-22 07:24:15+00:00       221.8846  40.378157  40.442510         9.8   \n",
       "\n",
       "                           hrv_pnni_50  hrv_nni_20  ...  \\\n",
       "2017-05-22 07:23:35+00:00    24.735490        36.6  ...   \n",
       "2017-05-22 07:23:45+00:00    17.384988        33.2  ...   \n",
       "2017-05-22 07:23:55+00:00    17.478992        30.8  ...   \n",
       "2017-05-22 07:24:05+00:00    16.732026        30.0  ...   \n",
       "2017-05-22 07:24:15+00:00    17.112367        35.4  ...   \n",
       "\n",
       "                           eda_phasic_n_below_mean  eda_phasic_n_sign_changes  \\\n",
       "2017-05-22 07:23:35+00:00                    140.0                        2.0   \n",
       "2017-05-22 07:23:45+00:00                    139.0                        1.0   \n",
       "2017-05-22 07:23:55+00:00                    143.0                        2.0   \n",
       "2017-05-22 07:24:05+00:00                    169.0                        3.0   \n",
       "2017-05-22 07:24:15+00:00                    181.0                        3.0   \n",
       "\n",
       "                           eda_phasic_iqr  eda_phasic_iqr_5_95  \\\n",
       "2017-05-22 07:23:35+00:00        0.020587             0.040621   \n",
       "2017-05-22 07:23:45+00:00        0.020038             0.036476   \n",
       "2017-05-22 07:23:55+00:00        0.019996             0.041045   \n",
       "2017-05-22 07:24:05+00:00        0.005211             0.034263   \n",
       "2017-05-22 07:24:15+00:00        0.007953             0.047757   \n",
       "\n",
       "                           eda_phasic_pct_5  eda_phasic_pct_95  \\\n",
       "2017-05-22 07:23:35+00:00         -0.004735           0.035887   \n",
       "2017-05-22 07:23:45+00:00          0.000085           0.036560   \n",
       "2017-05-22 07:23:55+00:00         -0.001636           0.039409   \n",
       "2017-05-22 07:24:05+00:00         -0.004960           0.029303   \n",
       "2017-05-22 07:24:15+00:00         -0.000006           0.047751   \n",
       "\n",
       "                           eda_phasic_entropy  eda_phasic_perm_entropy  \\\n",
       "2017-05-22 07:23:35+00:00                -inf                 0.957863   \n",
       "2017-05-22 07:23:45+00:00            4.933534                 0.885883   \n",
       "2017-05-22 07:23:55+00:00                -inf                 0.875543   \n",
       "2017-05-22 07:24:05+00:00                -inf                 0.726963   \n",
       "2017-05-22 07:24:15+00:00                -inf                 0.709955   \n",
       "\n",
       "                           eda_phasic_svd_entropy  label  \n",
       "2017-05-22 07:23:35+00:00                0.589850      0  \n",
       "2017-05-22 07:23:45+00:00                0.587246      0  \n",
       "2017-05-22 07:23:55+00:00                0.591086      0  \n",
       "2017-05-22 07:24:05+00:00                0.736138      0  \n",
       "2017-05-22 07:24:15+00:00                0.680942      0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the final dataframe that store the features of all participants and the label\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# loop through all the participants\n",
    "for user in range(2, 18):\n",
    "    if user == 12:\n",
    "        continue\n",
    "\n",
    "    # get the start time of the experiment\n",
    "    start_time = start_time_dict[user]\n",
    "    # get the start time of the baseline activity\n",
    "    baseline_start = stress_interval_dict[user][\"baseline\"][\"start\"]\n",
    "    # get the end time of the baseline activity\n",
    "    baseline_end = stress_interval_dict[user][\"baseline\"][\"end\"]\n",
    "    # get the start time of the stress activity\n",
    "    stress_start = stress_interval_dict[user][\"stress\"][\"start\"]\n",
    "    # get the end time of the stress activity\n",
    "    stress_end = stress_interval_dict[user][\"stress\"][\"end\"]\n",
    "    # get the features dataframe of the user\n",
    "    features = features_dict[user]\n",
    "    # get the baseline features dataframe\n",
    "    baseline_features = features.loc[start_time + baseline_start: start_time + baseline_end]\n",
    "    # get the stress features dataframe\n",
    "    stress_features = features.loc[start_time + stress_start: start_time + stress_end]\n",
    "     # ignore the warning of concat since it can be lengthy to look at\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        # add a column to the baseline features dataframe, the value is 0\n",
    "        baseline_features[\"label\"] = 0\n",
    "        # add a column to the stress features dataframe, the value is 1\n",
    "        stress_features[\"label\"] = 1\n",
    "        # add the user id to the baseline features dataframe, move the column to the first column\n",
    "        baseline_features.insert(0, \"user\", user)\n",
    "        # add the user id to the stress features dataframe, move the column to the first column\n",
    "        stress_features.insert(0, \"user\", user)\n",
    "        # concatenate the baseline features dataframe and the stress features dataframe\n",
    "        user_df = pd.concat([baseline_features, stress_features])\n",
    "        # concatenate the user dataframe to the final dataframe\n",
    "        final_df = pd.concat([final_df, user_df])\n",
    "\n",
    "# print out the final dataframe\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of my convenience, I'll save the final clean dataframe into a csv file, inside the [/data/filtered](../data/filtered/) folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final dataframe to a csv file inside the data/filtered folder\n",
    "final_df.to_csv(ROOT_DIR + \"/data/filtered/filtered_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train classifier and evaluate the performance\n",
    "\n",
    "The last step of this project is to train the classifier on the clean data we just created and evaluate the performances of machine learning models. For this project, I will be using SVM for classification, since the features are continuous.\n",
    "\n",
    "In this notebook, we will be using the leave-one-subject-out cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>num_ibis</th>\n",
       "      <th>hrv_mean_nni</th>\n",
       "      <th>hrv_median_nni</th>\n",
       "      <th>hrv_range_nni</th>\n",
       "      <th>hrv_sdsd</th>\n",
       "      <th>hrv_rmssd</th>\n",
       "      <th>hrv_nni_50</th>\n",
       "      <th>hrv_pnni_50</th>\n",
       "      <th>...</th>\n",
       "      <th>eda_phasic_n_below_mean</th>\n",
       "      <th>eda_phasic_n_sign_changes</th>\n",
       "      <th>eda_phasic_iqr</th>\n",
       "      <th>eda_phasic_iqr_5_95</th>\n",
       "      <th>eda_phasic_pct_5</th>\n",
       "      <th>eda_phasic_pct_95</th>\n",
       "      <th>eda_phasic_entropy</th>\n",
       "      <th>eda_phasic_perm_entropy</th>\n",
       "      <th>eda_phasic_svd_entropy</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-22 07:23:35+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>61.8</td>\n",
       "      <td>767.133553</td>\n",
       "      <td>775.0356</td>\n",
       "      <td>234.3860</td>\n",
       "      <td>47.967353</td>\n",
       "      <td>47.996281</td>\n",
       "      <td>15.4</td>\n",
       "      <td>24.735490</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>0.040621</td>\n",
       "      <td>-0.004735</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.957863</td>\n",
       "      <td>0.589850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-22 07:23:45+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>57.2</td>\n",
       "      <td>773.805869</td>\n",
       "      <td>781.2860</td>\n",
       "      <td>234.3860</td>\n",
       "      <td>42.033322</td>\n",
       "      <td>42.051298</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.384988</td>\n",
       "      <td>...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>4.933534</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>0.587246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-22 07:23:55+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>778.318170</td>\n",
       "      <td>781.2860</td>\n",
       "      <td>234.3860</td>\n",
       "      <td>41.279268</td>\n",
       "      <td>41.281592</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.478992</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>-0.001636</td>\n",
       "      <td>0.039409</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.875543</td>\n",
       "      <td>0.591086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-22 07:24:05+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>52.8</td>\n",
       "      <td>792.254337</td>\n",
       "      <td>790.6610</td>\n",
       "      <td>215.6348</td>\n",
       "      <td>39.361808</td>\n",
       "      <td>39.396494</td>\n",
       "      <td>8.8</td>\n",
       "      <td>16.732026</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.034263</td>\n",
       "      <td>-0.004960</td>\n",
       "      <td>0.029303</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.726963</td>\n",
       "      <td>0.736138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-22 07:24:15+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>800.842850</td>\n",
       "      <td>796.9110</td>\n",
       "      <td>221.8846</td>\n",
       "      <td>40.378157</td>\n",
       "      <td>40.442510</td>\n",
       "      <td>9.8</td>\n",
       "      <td>17.112367</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>0.047757</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.047751</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.709955</td>\n",
       "      <td>0.680942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Unnamed: 0  user  num_ibis  hrv_mean_nni  hrv_median_nni  \\\n",
       "0  2017-05-22 07:23:35+00:00     2      61.8    767.133553        775.0356   \n",
       "1  2017-05-22 07:23:45+00:00     2      57.2    773.805869        781.2860   \n",
       "2  2017-05-22 07:23:55+00:00     2      53.0    778.318170        781.2860   \n",
       "3  2017-05-22 07:24:05+00:00     2      52.8    792.254337        790.6610   \n",
       "4  2017-05-22 07:24:15+00:00     2      57.0    800.842850        796.9110   \n",
       "\n",
       "   hrv_range_nni   hrv_sdsd  hrv_rmssd  hrv_nni_50  hrv_pnni_50  ...  \\\n",
       "0       234.3860  47.967353  47.996281        15.4    24.735490  ...   \n",
       "1       234.3860  42.033322  42.051298        10.0    17.384988  ...   \n",
       "2       234.3860  41.279268  41.281592         9.2    17.478992  ...   \n",
       "3       215.6348  39.361808  39.396494         8.8    16.732026  ...   \n",
       "4       221.8846  40.378157  40.442510         9.8    17.112367  ...   \n",
       "\n",
       "   eda_phasic_n_below_mean  eda_phasic_n_sign_changes  eda_phasic_iqr  \\\n",
       "0                    140.0                        2.0        0.020587   \n",
       "1                    139.0                        1.0        0.020038   \n",
       "2                    143.0                        2.0        0.019996   \n",
       "3                    169.0                        3.0        0.005211   \n",
       "4                    181.0                        3.0        0.007953   \n",
       "\n",
       "   eda_phasic_iqr_5_95  eda_phasic_pct_5  eda_phasic_pct_95  \\\n",
       "0             0.040621         -0.004735           0.035887   \n",
       "1             0.036476          0.000085           0.036560   \n",
       "2             0.041045         -0.001636           0.039409   \n",
       "3             0.034263         -0.004960           0.029303   \n",
       "4             0.047757         -0.000006           0.047751   \n",
       "\n",
       "   eda_phasic_entropy  eda_phasic_perm_entropy  eda_phasic_svd_entropy  label  \n",
       "0                -inf                 0.957863                0.589850      0  \n",
       "1            4.933534                 0.885883                0.587246      0  \n",
       "2                -inf                 0.875543                0.591086      0  \n",
       "3                -inf                 0.726963                0.736138      0  \n",
       "4                -inf                 0.709955                0.680942      0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data files from the data/filtered folder\n",
    "filtered_features = pd.read_csv(ROOT_DIR + \"/data/filtered/filtered_features.csv\", index_col=False)\n",
    "filtered_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SVC does not accept the NaN values, we want to examine how many datapoints in our dataset contains NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with Nan values:  14\n",
      "Total number of rows:  4065\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows with NaN values\n",
    "print(\"Number of rows with Nan values: \", filtered_features.isna().any(axis=1).sum())\n",
    "print(\"Total number of rows: \", filtered_features.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't many rows with NaN values, so I will just drop them instead of trying to impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with Nan values (after dropping):  0\n"
     ]
    }
   ],
   "source": [
    "# drop the rows with NaN values\n",
    "filtered_features = filtered_features.dropna()\n",
    "# check the number of rows with NaN values after dropping\n",
    "print(\"Number of rows with Nan values (after dropping): \", filtered_features.isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to replace any values inf or -inf with a very large/small float64 number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the inf values with very large numbers\n",
    "filtered_features = filtered_features.replace([np.inf], 1e9)\n",
    "# replace the -inf values with very small numbers\n",
    "filtered_features = filtered_features.replace([-np.inf], -1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to check the number of data points in each class just to make sure we have a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2521\n",
       "1    1530\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of samples for each label\n",
    "filtered_features[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below initialize the cross validation methods and the necessary lists to store the metrics. I will record the accuracy, f1 score, precision, recal and AUROC scores for each fold and report the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the LOGO cross validation\n",
    "logo = LeaveOneGroupOut()\n",
    "# initialize the list that store the accuracy of each fold\n",
    "accuracy_list = []\n",
    "# initialize the list that store the confusion matrix of each fold\n",
    "confusion_matrix_list = []\n",
    "# initialize the list that store the f1 score of each fold\n",
    "f1_list = []\n",
    "# initialize the list that store the precision of each fold\n",
    "precision_list = []\n",
    "# initialize the list that store the recall of each fold\n",
    "recall_list = []\n",
    "# initialize the list that store the roc_auc of each fold\n",
    "roc_auc_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to apply SMOTE to the training data\n",
    "def apply_smote(X_train, y_train):\n",
    "    '''\n",
    "    Apply SMOTE to the training data\n",
    "    :param X_train: the training features\n",
    "    :param y_train: the training labels\n",
    "    :return: the oversampled training features and labels\n",
    "    '''\n",
    "    # apply SMOTE\n",
    "    sm = SMOTE(random_state=42, sampling_strategy='minority', n_jobs=-1)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    # return the new training data\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the training and evaluation part ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data label count:  Counter({0: 2326, 1: 1386})\n",
      "Prediction label count:  Counter({0: 328, 1: 11})\n",
      "Training data label count:  Counter({0: 2331, 1: 1392})\n",
      "Prediction label count:  Counter({0: 253, 1: 75})\n",
      "Training data label count:  Counter({0: 2366, 1: 1453})\n",
      "Prediction label count:  Counter({1: 161, 0: 71})\n",
      "Training data label count:  Counter({0: 2361, 1: 1453})\n",
      "Prediction label count:  Counter({0: 131, 1: 106})\n",
      "Training data label count:  Counter({0: 2342, 1: 1404})\n",
      "Prediction label count:  Counter({0: 301, 1: 4})\n",
      "Training data label count:  Counter({0: 2376, 1: 1468})\n",
      "Prediction label count:  Counter({0: 178, 1: 29})\n",
      "Training data label count:  Counter({0: 2368, 1: 1459})\n",
      "Prediction label count:  Counter({0: 140, 1: 84})\n",
      "Training data label count:  Counter({0: 2348, 1: 1403})\n",
      "Prediction label count:  Counter({0: 243, 1: 57})\n",
      "Training data label count:  Counter({0: 2370, 1: 1459})\n",
      "Prediction label count:  Counter({0: 179, 1: 43})\n",
      "Training data label count:  Counter({0: 2340, 1: 1398})\n",
      "Prediction label count:  Counter({0: 283, 1: 30})\n",
      "Training data label count:  Counter({0: 2371, 1: 1452})\n",
      "Prediction label count:  Counter({0: 228})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data label count:  Counter({0: 2333, 1: 1394})\n",
      "Prediction label count:  Counter({0: 177, 1: 147})\n",
      "Training data label count:  Counter({0: 2371, 1: 1462})\n",
      "Prediction label count:  Counter({0: 170, 1: 48})\n",
      "Training data label count:  Counter({0: 2333, 1: 1391})\n",
      "Prediction label count:  Counter({1: 248, 0: 79})\n",
      "Training data label count:  Counter({0: 2358, 1: 1446})\n",
      "Prediction label count:  Counter({0: 158, 1: 89})\n",
      "Average accuracy:  0.5956003758517768\n",
      "Average f1 score:  0.33099188231381466\n",
      "Average precision:  0.43411347596369515\n",
      "Average recall:  0.331126508577229\n",
      "Average roc_auc:  0.5428405563176487\n"
     ]
    }
   ],
   "source": [
    "# creating the fold for the cross validation according to the user id\n",
    "groups = filtered_features[\"user\"].values\n",
    "\n",
    "# get the X and y, dropping the user id column and the label column and index column\n",
    "X = filtered_features.drop([\"user\", \"label\", \"Unnamed: 0\"], axis=1)\n",
    "y = filtered_features[\"label\"]\n",
    "\n",
    "# loop through the fold\n",
    "for train_index, test_index in logo.split(X, y, groups):\n",
    "    # get the X_train, X_test, y_train, y_test\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # try scaling the data\n",
    "    # X_train = StandardScaler().fit_transform(X_train)\n",
    "    # X_test = StandardScaler().fit_transform(X_test)\n",
    "    # apply SMOTE to the training data\n",
    "    # X_train, y_train = apply_smote(X_train, y_train)\n",
    "    # initialize the random forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "    # get the prediction of the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # count the labels of the prediction and the training data\n",
    "    print(\"Training data label count: \", Counter(y_train))\n",
    "    print(\"Prediction label count: \", Counter(y_pred))\n",
    "    # get the accuracy of the prediction\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # get the confusion matrix of the prediction\n",
    "    # confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # get the f1 score of the prediction\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # get the precision of the prediction\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    # get the recall of the prediction\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    # get the roc_auc of the prediction\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    # append the accuracy to the accuracy list\n",
    "    accuracy_list.append(accuracy)\n",
    "    # append the confusion matrix to the confusion matrix list\n",
    "    # confusion_matrix_list.append(confusion_matrix)\n",
    "    # append the f1 score to the f1 list\n",
    "    f1_list.append(f1)\n",
    "    # append the precision to the precision list\n",
    "    precision_list.append(precision)\n",
    "    # append the recall to the recall list\n",
    "    recall_list.append(recall)\n",
    "    # append the roc_auc to the roc_auc list\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "\n",
    "# print out the average accuracy, average f1 score, average precision, average recall, average roc_auc\n",
    "print(\"Average accuracy: \", np.mean(accuracy_list))\n",
    "print(\"Average f1 score: \", np.mean(f1_list))\n",
    "print(\"Average precision: \", np.mean(precision_list))\n",
    "print(\"Average recall: \", np.mean(recall_list))\n",
    "print(\"Average roc_auc: \", np.mean(roc_auc_list))\n",
    "\n",
    "# print out the confusion matrix of the first fold\n",
    "# confusion_matrix_list[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
